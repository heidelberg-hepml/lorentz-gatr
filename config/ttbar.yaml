exp_type: ttbar
exp_name: ttbar_local_debug
base_dir: /media/jspinner/shared/Studium/project3/lorentz-gatr

data:
 n_jets: [0]
 data_path_0j: /media/jspinner/shared/Studium/project3/data/ttbar_0j.npy
 data_path_1j: /media/jspinner/shared/Studium/project3/data/ttbar_1j.npy
 data_path_2j: /media/jspinner/shared/Studium/project3/data/ttbar_2j.npy
 data_path_3j: /media/jspinner/shared/Studium/project3/data/ttbar_3j.npy
 data_path_4j: /media/jspinner/shared/Studium/project3/data/ttbar_4j.npy
 subsample: 100000
 train_test_val: [.5, .4, .1]
 base_type: 2
 use_delta_r_min: true
 use_pt_min: true

odeint:
 method: rk4
 rtol: 1e-5
 atol: 1e-5
 options:
  step_size: 0.01

cfm:
 embed_t_dim: 8
 embed_t_scale: 30.
 hutchinson: true
 coordinates_straight: ${cfm.coordinates_sampling}
 coordinates_network: Fourmomenta
 coordinates_sampling: StandardLogPtPhiEtaLogM2
 transforms_float64: true

training:
 iterations: 50
 batchsize: 1024
 scheduler: ReduceLROnPlateau

evaluation:
 sample: true
 save_samples: false
 nsamples: 1000
 batchsize: 1024
 eval_loss: []
 eval_log_prob: [] # expensive
 classifier: true

plot: true
plotting:
 loss: true
 fourmomenta: true
 jetmomenta: true
 preprocessed: true
 virtual: true
 delta: true
 deta_dphi: true
 save_trajectories: false
 log_prob: true
 reweighted: true
 create_mask: false

defaults:
- model: gatr_eventgen
- classifier: classifier
- default
- hydra
- _self_