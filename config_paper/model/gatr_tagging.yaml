_target_: experiments.tagging.wrappers.TaggingGATrWrapper
force_xformers: '${training.force_xformers}'
mean_aggregation: false

net:
 _target_: gatr.nets.GATr

 in_mv_channels: 1
 out_mv_channels: 1
 hidden_mv_channels: 16

 in_s_channels: 0
 out_s_channels: 1
 hidden_s_channels: 32

 num_blocks: 12
 reinsert_mv_channels: null
 reinsert_s_channels: null
 dropout_prob: null
 double_layernorm: false

 attention:
  num_heads: 8
  multi_query: false
  increase_hidden_channels: 2
  head_scale: true

defaults:
 - /base_attention@net.attention
 - /base_mlp@net.mlp
